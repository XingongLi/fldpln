{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to fldpln","text":"<p>Flood inundation modeling and mapping using the FLDPLN model</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://xingongli.github.io/fldpln</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"common/","title":"common module","text":"<p>The common module contains common variables, functions and classes used by the other modules.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/xingongli/fldpln/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>fldpln could always use more documentation, whether as part of the official fldpln docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/xingongli/fldpln/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up fldpln for local development.</p> <ol> <li> <p>Fork the fldpln repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/fldpln.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv fldpln\n$ cd fldpln/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 fldpln tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/xingongli/fldpln/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"fldpln/","title":"fldpln module","text":"<p>Main module.</p>"},{"location":"gauge/","title":"gauge module","text":"<p>Module for handling gauge data for flood mapping</p>"},{"location":"gauge/#fldpln.gauge.GetUsgsGauges","title":"<code>GetUsgsGauges(geobox, epsg=32614)</code>","text":"<p>Get USGS gauges within a box and project them</p> <p>Parameters:</p> Name Type Description Default <code>geobox</code> <p>a geographic box of (minX,minY,maxX,maxY)</p> required <code>epsg</code> <p>projected coordinate system, default to UTM14 (epsg=32614) for Kansas</p> <code>32614</code> Source code in <code>fldpln/gauge.py</code> <pre><code>def GetUsgsGauges(geobox, epsg=32614):\n    \"\"\"Get USGS gauges within a box and project them\n        Parameters:\n            geobox: a geographic box of (minX,minY,maxX,maxY)\n            epsg: projected coordinate system, default to UTM14 (epsg=32614) for Kansas\n        Returns: a dataframe of USGS gauges\n    \"\"\"\n\n    # USGS site/gauge table fields:\n    #  agency_cd       -- Agency\n    #  site_no         -- Site identification number\n    #  station_nm      -- Site name\n    #  site_tp_cd      -- Site type\n    #  dec_lat_va      -- Decimal latitude\n    #  dec_long_va     -- Decimal longitude\n    #  coord_acy_cd    -- Latitude-longitude accuracy\n    #  dec_coord_datum_cd -- Decimal Latitude-longitude datum\n    #  alt_va          -- Altitude of gauge/land surface\n    #  alt_acy_va      -- Altitude accuracy\n    #  alt_datum_cd    -- Altitude datum\n    #  huc_cd          -- Hydrologic unit code\n    #\n    # # read in USGS gauges from Excel file which is manually generated from USGS gauge web site\n    # # See Chapter 5 in book Flood Mapping in Kansas.\n    # # This can be automated too!\n    # gaugeExcelFile = 'usgs_gauges_ks_nearby.xlsx'\n    # sheetName = 'usgs_gauges_ks_nearby'\n    # gdf = pd.read_excel(gaugeExcelFile, sheet_name=sheetName,dtype={'site_no':str,'huc_cd':str})\n    # # print('USGS gauges from web:',gdf)\n\n    # USGS Site Web Service\n    usgsSiteServiceUrl = 'http://waterservices.usgs.gov/nwis/site'\n\n    # prepare a query URL to retrieve active lake and stream USGS gauges with instantaneous values\n    # usgsSiteServiceUrl = 'http://waterservices.usgs.gov/nwis/site/?format=rdb,1.0&amp;bBox=-99.610000,36.810000,-94.200000,40.250000&amp;siteType=LK,ST&amp;siteStatus=active&amp;hasDataTypeCd=iv'\n    # parameters\n    bBox = ','.join([str(c) for c in geobox])\n    params = {'format':'rdb', 'bBox':bBox, 'siteType': 'LK,ST', 'siteStatus':'active', 'hasDataTypeCd': 'iv'}\n\n    # Send the request with the get method\n    response = requests.get(usgsSiteServiceUrl, params=params, verify=False)\n    print(response.request.url)\n\n    # turn content into list of lines\n    contentLst = response.text.split('\\n')\n\n    # find the number of lines of the header in the RDB file\n    numOfHeaderLn = 0\n    for ln in contentLst:\n        if ln[0] == '#':\n            numOfHeaderLn += 1\n        else:\n            break\n\n    # get field names\n    fieldNames = contentLst[numOfHeaderLn].split('\\t')\n    # print(fieldNames)\n\n    # turn each line into a list\n    gLst = [row.split('\\t') for row in contentLst[numOfHeaderLn+2:-1]]\n    # convert lat, longitude, and datum elevation to floats\n    for g in gLst:\n        g[4] = float(g[4])\n        g[5] = float(g[5])\n        if g[8] != '':\n            g[8] = float(g[8])\n        else:\n            g[8] = None\n        if g[9] != '':\n            g[9] = float(g[9])\n        else:\n            g[9] = None\n\n    # create a df from the list\n    gdf = pd.DataFrame(gLst, columns=fieldNames)\n\n    # turn pd into gpd using gauge's latitude and longitude coordinates\n    ggdf = gpd.GeoDataFrame(gdf, geometry=gpd.points_from_xy(gdf.dec_long_va, gdf.dec_lat_va))\n\n    # Project gauge location \n    # define gauge CRS, i.e., GCS on NAD83, assuming all USGS gauges are based on NAD83\n    ggdf = ggdf.set_crs(epsg=4326)\n    # project ggdf to library coordinate system, i.e., UTM 14N\n    ggdf = ggdf.to_crs(epsg=epsg)\n    # save the projected shapefile\n    # ggdf.to_file(shpFullName)\n\n    # add gauge's coordinates as fields\n    ggdf['x'] = ggdf['geometry'].x\n    ggdf['y'] = ggdf['geometry'].y\n\n    # USGS gauges in UTM 14N\n    gdf = ggdf.drop(columns=['geometry'])\n    # print('Gauges with UTM 14N coordinates:',gdf)\n    # print(f'Total gauges: {len(gdf)}')\n\n    return gdf\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install fldpln, run this command in your terminal:</p> <pre><code>pip install fldpln\n</code></pre> <p>This is the preferred method to install fldpln, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install fldpln from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/xingongli/fldpln\n</code></pre>"},{"location":"mapping/","title":"mapping module","text":"<p>Module for mapping tile-based library .</p>"},{"location":"mapping/#fldpln.mapping.CreateFolders","title":"<code>CreateFolders(outFolder, scratchFolderName='scratch', outMapFolderName='maps', removeExist=True)</code>","text":"<p>Create folders for storing temporary files and output maps</p> <p>Parameters:</p> Name Type Description Default <code>outFolder</code> <p>output folder</p> required <code>scratchFolderName</code> <p>name of the folder for storing temporary files</p> <code>'scratch'</code> <code>outMapFolderName</code> <p>name of the folder for storing output maps</p> <code>'maps'</code> <code>removeExist</code> <p>bool whether to remove existing folders</p> <code>True</code> Source code in <code>fldpln/mapping.py</code> <pre><code>def CreateFolders(outFolder,scratchFolderName='scratch',outMapFolderName='maps',removeExist=True):\n    \"\"\" Create folders for storing temporary files and output maps\n        Parameters:\n            outFolder: output folder\n            scratchFolderName: name of the folder for storing temporary files\n            outMapFolderName: name of the folder for storing output maps\n            removeExist: bool whether to remove existing folders\n        Returns: folder names for storing output maps and temporary files\n    \"\"\"\n    # create output folder if it doesn't exist\n    os.makedirs(outFolder, exist_ok=True)\n\n    # scratch folder\n    scratchFolder = os.path.join(outFolder, scratchFolderName)\n    # map output folder\n    outMapFolder = os.path.join(outFolder, outMapFolderName)\n\n    # Create the folders for storing temp and output files\n    if removeExist:\n        if os.path.isdir(scratchFolder): shutil.rmtree(scratchFolder)\n        if os.path.isdir(outMapFolder): shutil.rmtree(outMapFolder)\n\n    os.makedirs(scratchFolder, exist_ok=True)\n    os.makedirs(outMapFolder, exist_ok=True)\n\n    return outMapFolder,scratchFolder\n</code></pre>"},{"location":"tile/","title":"tile module","text":"<p>Module to re-organize FLDPLN segment-based library into tile-based library for fast mapping</p>"},{"location":"tile/#fldpln.tile.CalculateFspSegmentDownstreamDistance","title":"<code>CalculateFspSegmentDownstreamDistance(libFolder, libName)</code>","text":"<p>Cleanup segments (some segments don't exist in FSPs) and save library FSP and segment information as two csv files (fsp_info.csv &amp; segment_info.csv).  It also reads in the SpatialReference.prj and save it in CellSizeSpatialReference.json. It also calculates FSP and segment downstream distance (i.e., distance to library outlet(s))  which involves:     1. Calculate FSP's within-segment downstream distance     2. Calculate segment length which is more accurate than \"CellCount\" * cell size     3. Calculate segment's downstream distance (to watershed outlet) for speeding up      4. Calculate FSP's downstream distance Note that FSPs and segments are based on raster cell centers. Segment and its downstream segment has a gap (1 cell or sqrt(2) cell).</p> <p>Parameters:</p> Name Type Description Default <code>libFolder</code> <p>folder containing the library</p> required <code>libName</code> <p>library name</p> required Source code in <code>fldpln/tile.py</code> <pre><code>def CalculateFspSegmentDownstreamDistance(libFolder,libName):\n    \"\"\" Cleanup segments (some segments don't exist in FSPs) and save library FSP and segment information as two csv files (fsp_info.csv &amp; segment_info.csv). \n        It also reads in the SpatialReference.prj and save it in CellSizeSpatialReference.json. It also calculates FSP and segment downstream distance (i.e., distance to library outlet(s)) \n        which involves:\n            1. Calculate FSP's within-segment downstream distance\n            2. Calculate segment length which is more accurate than \"CellCount\" * cell size\n            3. Calculate segment's downstream distance (to watershed outlet) for speeding up \n            4. Calculate FSP's downstream distance\n        Note that FSPs and segments are based on raster cell centers. Segment and its downstream segment has a gap (1 cell or sqrt(2) cell).\n        Parameters:\n            libFolder: folder containing the library\n            libName: library name\n        Return: FSP and segment data frames\n    \"\"\"\n\n    #\n    # read in fsp (flood source pixel) and segment network info Excel files\n    #\n    # fspInfoColumnNames = ['FspX','FspY','SegId','FilledElev'], columns 'DsDist' will be calculated by this function\n    # segInfoColumnNames = ['SegId','CellCount','DsSegId', 'StFac','EdFac'], columns 'Length','DsDist' will be added by this function\n    fspInfoFile = os.path.join(libFolder, libName, fspInfoFileName)\n    segInfoFile = os.path.join(libFolder, libName, segInfoFileName)\n\n\n    # read in FSP ID and coordinates\n    # need to set float_precision='round_trip' to prevent rounding while reading the text file! float_precision='high' DOESN'T work.\n    # For Verdigris 10-m library, FSP ID of 22246, its FspX of -1003.7918248322967 in fsp_info.csv was read into memory as -1003.7918248322968 without using float_precision='round_trip'\n    fspDf = pd.read_csv(fspInfoFile,float_precision='round_trip',index_col=False)\n    segDf = pd.read_csv(segInfoFile,float_precision='round_trip',index_col=False)\n\n    #\n    # Clean up the segment table.\n    # 1. Remove the segment if it's not in the FSP table\n    # 2. If the missing segment is the downstream segment of another segment, set it as 0. \n    # Those missing segments are usually because of they are close to or in waterbodies. \n    # By removing those segment, a library may have several separate watersheds/outlets!\n    #\n    # get the segment IDs\n    segIds = segDf['SegId'].to_list()\n    for sid in segIds:\n        fsps = fspDf[fspDf['SegId']==sid]\n        if len(fsps)==0:\n            # segment not found in the FSP table. delete the row\n            segDf = segDf.loc[segDf['SegId']!=sid]\n            # set downstream segment ID to 0\n            segDf.loc[segDf['DsSegId']==sid,'DsSegId'] = 0\n\n    #\n    # Calculate FSP within-segment distance, segment length, and segment dowstream distance, and FSP downstream distance\n    #\n    # add field for FSP within-segment distance\n    fspDf['DsDist'] = 0.0\n    # add field for segment length\n    segDf['Length'] = 0.0\n\n    # Calculate FSP within-segment DOWNSTREAM distance and segment length\n    for segIdx, row in segDf.iterrows():\n        segID = row['SegId']\n        # print(segID)\n\n        # select FSP on the segment\n        fsps = fspDf[fspDf['SegId']==segID][['FspX','FspY']]\n\n        # calculate fsp downstream within segment length\n        segDist = 0.0\n        if len(fsps)==0:\n            # this should not happen as we have already clean up the segment table!\n            print(f\"Segment {segID} is missing in {fspInfoFileName}!\")\n        else:  \n            first=True\n            for idx, row in fsps[::-1].iterrows():\n                # Note the idx in fsps is the index in fspDf!!!\n                # calculate distance\n                if first:\n                    fspx1, fspy1 = row['FspX'], row['FspY']\n                    dist=0.0\n                    first=False\n                else:\n                    fspx2, fspy2 = row['FspX'], row['FspY']\n                    dist=math.sqrt((fspx1-fspx2)**2+(fspy1-fspy2)**2)\n                    fspx1, fspy1 = fspx2, fspy2\n                segDist += dist\n                fspDf.at[idx,'DsDist']=segDist\n\n        # update segment distance in segDf\n        segDf.at[segIdx,'Length'] = segDist\n\n    # show the DFs\n    # print(fspDf[:1136])\n    # print(segDf)\n\n    #\n    # Calculate segment downstream length\n    #\n    # only for the segments that exist in the FSP table\n    # But this not necessary as segments don't exist in FSP table already removed\n    # Also this line will remove the segment which has just one FSP!\n    # segDf = segDf[segDf['Length']&gt;0]\n\n    # add field for segment downstream distance for speeding up calculating FSP downstream distance\n    segDf['DsDist'] = 0.0\n    for segIdx, row in segDf.iterrows():\n        segID = row['SegId']\n        dsSegID = row['DsSegId']\n\n        dsDist = 0.0\n        while dsSegID != 0:\n            # get downstream segment length and ID\n            tempDf = segDf[segDf['SegId']==dsSegID][['Length','DsSegId']]\n            length, segID_ds = tempDf.iat[0,0], tempDf.iat[0,1]\n            dsDist += length\n\n            # There is a GAP between two segments as they are consisted of FSP cell centers\n            # Calculate the GAP and add it to segment downstream dist\n            # last fsp in upstream segment\n            lastFspXy = fspDf[fspDf['SegId']==segID][['FspX','FspY']].tail(1)    \n            fspx1, fspy1 = lastFspXy.iat[0,0],lastFspXy.iat[0,1]\n            # first FSP in downstream segment\n            firstFspXy = fspDf[fspDf['SegId']==dsSegID][['FspX','FspY']].head(1)\n            fspx2, fspy2 = firstFspXy.iat[0,0], firstFspXy.iat[0,1]\n            dist=math.sqrt((fspx1-fspx2)**2+(fspy1-fspy2)**2)\n            dsDist += dist\n\n            # move to ownstream segment\n            segID = dsSegID\n            dsSegID = segID_ds\n\n        segDf.at[segIdx,'DsDist'] = dsDist\n    # print(segDf)\n\n    # Calculate FSP downstream distance\n    for idx, row in fspDf.iterrows():\n        segID = row['SegId']\n        inSegDist = row['DsDist']\n\n        # get segment downstream distance\n        tempDf = segDf[segDf['SegId']==segID][['DsDist']]\n        segDsDist = tempDf.iat[0,0]\n\n        # reset FSP downstream distance\n        fspDf.at[idx,'DsDist'] = inSegDist + segDsDist\n    # print(fspDf)\n\n    # save the updated info files\n    fspDf.to_csv(fspInfoFile,index=False,mode='w+')\n    segDf.to_csv(segInfoFile,index=False,mode='w+')\n\n    return fspDf, segDf\n</code></pre>"},{"location":"tile/#fldpln.tile.CalculateLibraryExtent","title":"<code>CalculateLibraryExtent(segLibFolder, cellSize)</code>","text":"<p>Calculate library external border extent</p> <p>Parameters:</p> Name Type Description Default <code>segLibFolder</code> <p>folder containing the segment-based library</p> required <code>cellSize</code> <p>cell size in meters</p> required Source code in <code>fldpln/tile.py</code> <pre><code>def CalculateLibraryExtent(segLibFolder, cellSize):\n    \"\"\" Calculate library external border extent\n        Parameters:\n            segLibFolder: folder containing the segment-based library\n            cellSize: cell size in meters\n        Return: external border extent (minX, maxX,minY, maxY) and segment extents (FPP cell center) data frame of ['MinX','MaxX','MinY','MaxY','FileName']\n    \"\"\"\n\n    # Get all the segment mat files in the library/watershed\n    segMatFileFullNames = glob.glob(os.path.join(segLibFolder, segMatFileMainName+'*.mat'))\n    hcs = cellSize/2\n\n    # initialize extent\n    minX,maxX,minY,maxY = (math.inf,-math.inf,math.inf,-math.inf)\n    relNum = 0 # number of FSP-FPP relation\n    segExts = pd.DataFrame(columns=['MinX','MaxX','MinY','MaxY','FileName']) # empty df storing each segment's FPP extent and corresponding mat file name\n    # update the extent by all the segments\n    print('Calculate library extent ...')\n    for mf in segMatFileFullNames:\n        # read mat file\n        matVar = ReadMatFile(mf,matRelVarName)\n        # converting array to a dataframe\n        df = pd.DataFrame(matVar, columns=matRelColumnNames)\n\n        relNum += len(df)\n        # print('Segment:', segId, 'Number of FSP-FPP relations:', len(df))\n\n        # Calculate segment external border extent\n        sminX = df['floodplain_pixel_x'].min()-hcs\n        sminY = df['floodplain_pixel_y'].min()-hcs\n        smaxX = df['floodplain_pixel_x'].max()+hcs\n        smaxY = df['floodplain_pixel_y'].max()+hcs\n        segExt= pd.DataFrame([[sminX,smaxX,sminY,smaxY,mf]],columns=['MinX','MaxX','MinY','MaxY','FileName'])\n        # add the segment extent to the df\n        # segExts = segExts.append(segExt)\n        segExts = pd.concat([segExts,segExt])\n\n        #update library extent\n        if sminX &lt; minX: minX = sminX\n        if sminY &lt; minY: minY = sminY\n        if smaxX &gt; maxX: maxX = smaxX\n        if smaxY &gt; maxY: maxY = smaxY\n\n    print('Library external border extent (minX, maxX, minY, maxY) :',(minX, maxX,minY, maxY))\n    # print('Library segment FPP extents:\\n', segExts)\n    print('Total number of FSP-FPP relations:', relNum)\n\n    return (minX, maxX,minY, maxY), segExts \n</code></pre>"},{"location":"tile/#fldpln.tile.CalculateTileBoundary","title":"<code>CalculateTileBoundary(minX, maxX, minY, maxY, tileSizeX, tileSizeY, padding=True)</code>","text":"<p>Calculate each tile's boundary as (minX, maxX,minY, maxY)</p> <p>Parameters:</p> Name Type Description Default <code>minX,</code> <code>maxX, minY, maxY</code> <p>external border (not the cell center) coordinates of the area needs to be tiled.</p> required <code>tileSizeX,</code> <code>tileSizeY</code> <p>external border size of a tile, not the cell center size!</p> required <code>padding</code> <p>all the tiles have the same size, not reduced to the border of the tiled area. default is True.</p> <code>True</code> Source code in <code>fldpln/tile.py</code> <pre><code>def CalculateTileBoundary(minX, maxX, minY, maxY, tileSizeX, tileSizeY, padding=True):\n    \"\"\" Calculate each tile's boundary as (minX, maxX,minY, maxY)\n        Parameters:\n            minX, maxX, minY, maxY: external border (not the cell center) coordinates of the area needs to be tiled.\n            tileSizeX, tileSizeY: external border size of a tile, not the cell center size!\n            padding: all the tiles have the same size, not reduced to the border of the tiled area. default is True.\n        Return: a list of tile boundary tuple of (minX, maxX,minY, maxY)\n    \"\"\"\n\n    # helper function to generate tile boundary in one dimension\n    def TileInOneDimension(min, max, tileSize, padding=True):\n        # generate tile marker coordinates\n        bs = np.arange(min, max, tileSize)\n        # handle the last coordinate as np.arange() is inclusive\n        if padding: #all the tiles have the same length whether it's outside the border of the tiled area or not\n            bs = np.append(bs, bs[-1]+tileSize)\n        else: # the last tile stops at the border of the area\n            bs = np.append(bs, max)\n\n        # generate tile border coordinate pairs\n        tb = [(bs[t], bs[t+1]) for t in range(bs.size-1)]\n        return tb\n\n    xb = TileInOneDimension(minX,maxX,tileSizeX,padding)\n    yb = TileInOneDimension(minY,maxY,tileSizeY,padding)\n    tb = [(x, y) for x in xb for y in yb] # in ((minX, maxX),(minY, maxY))\n    # convert to (minX, maxX,minY, maxY)\n    tb = [(minX, maxX,minY, maxY) for ((minX,maxX),(minY,maxY)) in tb]\n    return tb\n</code></pre>"},{"location":"tile/#fldpln.tile.GenerateSegmentShapefilesFromFspSegmentInfoFiles","title":"<code>GenerateSegmentShapefilesFromFspSegmentInfoFiles(segInfoFile, fspInfoFile, crs, outShpFile)</code>","text":"<p>Generate segment shapefiles from FSP and segment info files.</p> <p>Parameters:</p> Name Type Description Default <code>segInfoFile</code> <p>segment info file</p> required <code>fspInfoFile</code> <p>FSP info file</p> required <code>crs</code> <p>coordinate reference system</p> required <code>outShpFile</code> <p>output shapefile</p> required Source code in <code>fldpln/tile.py</code> <pre><code>def GenerateSegmentShapefilesFromFspSegmentInfoFiles(segInfoFile, fspInfoFile, crs, outShpFile):\n    \"\"\" Generate segment shapefiles from FSP and segment info files.\n        Parameters:\n            segInfoFile: segment info file\n            fspInfoFile: FSP info file\n            crs: coordinate reference system\n            outShpFile: output shapefile\n        Return: None\n    \"\"\"\n\n    # read in FSP ID and coordinates\n    # need to set float_precision='round_trip' to prevent rounding while reading the text file! float_precision='high' DOESN'T work.\n    # For Verdigris 10-m library, FSP ID of 22246, its FspX of -1003.7918248322967 in fsp_info.csv was read into memory as -1003.7918248322968 without using float_precision='round_trip'\n    # read column names\n    segColNames = pd.read_csv(segInfoFile, index_col=0, nrows=0).columns.tolist()\n    # read in all the segments\n    segDf = pd.read_csv(segInfoFile,float_precision='round_trip',index_col=False)\n\n    # read in FSP's SegId and its coordinates\n    fspDf = pd.read_csv(fspInfoFile,float_precision='round_trip',index_col=False)[['SegId','FspX','FspY']]\n\n    # Create segment geometry list using FSP coordinates on a segment\n    segGeometry = []\n    for row in segDf.itertuples(): # itertuples() is the fastest way of iterating a df\n        segID,dsSegID = (getattr(row,'SegId'),getattr(row,'DsSegId'))\n\n        # select FSP on the segment\n        fsps = fspDf[fspDf['SegId']==segID][['FspX','FspY']]\n\n        # There is a GAP between two segments as they are consisted of FSP cell centers\n        # Upstream sgements are EXTENDED to the first FSP of the downstream segment!\n        if dsSegID != 0:\n            # first FSP in downstream segment\n            firstFspXy = fspDf[fspDf['SegId']==dsSegID][['FspX','FspY']].head(1)\n            # append to the fsps\n            # fsps = fsps.append(firstFspXy)\n            fsps = pd.concat([fsps,firstFspXy])\n        # print(fsps)\n\n        # turn the FSPs into a LineString\n        # create Points, a GeometryArray, from fsps\n        points = gpd.points_from_xy(fsps['FspX'],fsps['FspY'])\n        segLineStr = LineString(points)\n        # print(segLineStr)\n\n        # Insert the line into the geometry list\n        segGeometry.append(segLineStr)\n\n    # create a geodataframe for writing shapefile\n    libSegs = gpd.GeoDataFrame(segDf, crs=crs, geometry=segGeometry)\n\n    # Write the data into that Shapefile\n    schema = gpd.io.file.infer_schema(libSegs)\n    for c in segColNames:\n        schema['properties'][c] = segColSchema[c]\n    libSegs.to_file(outShpFile, driver= \"ESRI Shapefile\",schema=schema) # existing shapefile will be replaced automatically!!!\n\n    return #libSegs\n</code></pre>"},{"location":"tile/#fldpln.tile.GetStreamOrdersForFspsSegments","title":"<code>GetStreamOrdersForFspsSegments(libFolder, strOrdShpFile, shpSegIdName, shpStrOrdColName)</code>","text":"<p>Get stream order for FSPs and segments from segment stream order shapefile and save them in fsp_info.csv and segment_info.csv files.  It also creates the stream_order_info.csv which stores the network info at the level of stream orders for FSP DOF interpolation</p> <p>Parameters:</p> Name Type Description Default <code>libFolder</code> <p>library folder</p> required <code>strOrdShpFile</code> <p>stream order shapefile</p> required <code>shpSegIdName</code> <p>segment ID column name in the shapefile</p> required <code>shpStrOrdColName</code> <p>stream order column name in the shapefile</p> required Source code in <code>fldpln/tile.py</code> <pre><code>def GetStreamOrdersForFspsSegments(libFolder,strOrdShpFile,shpSegIdName,shpStrOrdColName):\n    \"\"\" Get stream order for FSPs and segments from segment stream order shapefile and save them in fsp_info.csv and segment_info.csv files. \n        It also creates the stream_order_info.csv which stores the network info at the level of stream orders for FSP DOF interpolation\n        Parameters:\n            libFolder: library folder\n            strOrdShpFile: stream order shapefile\n            shpSegIdName: segment ID column name in the shapefile\n            shpStrOrdColName: stream order column name in the shapefile\n        Return: FSP, segment, and stream order data frames\n    \"\"\"\n\n    # get stream order from the shapefile\n    shpDf = gpd.read_file(strOrdShpFile)\n\n    # select columns\n    streamOrderColumns = [shpSegIdName,shpStrOrdColName]\n    segOrdDf = shpDf[streamOrderColumns]\n    # rename shp order column to 'StrOrd'\n    segOrdDf = segOrdDf.rename(columns={shpSegIdName: 'SegId', shpStrOrdColName: strOrdColName})\n    # print(segOrdDf)\n\n    # read fsp and segment info csv files\n    fspCsvFile = os.path.join(libFolder,fspInfoFileName)\n    segCsvFile = os.path.join(libFolder,segInfoFileName)\n    # need to set float_precision='round_trip' to prevent rounding while reading the text file! float_precision='high' DOESN'T work.\n    # For Verdigris 10-m library, FSP ID of 22246, its FspX of -1003.7918248322967 in fsp_info.csv was read into memory as -1003.7918248322968 without using float_precision='round_trip'\n    fspDf = pd.read_csv(fspCsvFile,float_precision='round_trip',index_col=False)\n    segDf = pd.read_csv(segCsvFile,float_precision='round_trip',index_col=False)\n\n    # remove existing \"StrOrd\" column\n    if ('StrOrd' in fspDf.columns):\n        fspDf.drop(['StrOrd'], axis=1,inplace=True)\n    if ('StrOrd' in segDf.columns):\n        segDf.drop(['StrOrd'], axis=1,inplace=True)\n\n    # Get segment stream order by merging DFs based on segment ID\n    segDf = pd.merge(segDf, segOrdDf, how='left', on='SegId')\n    # print(segDf)\n\n    # Get FSP's stream order by merging\n    fspDf = pd.merge(fspDf, segOrdDf, how='left', on='SegId')\n    # print(segDf)\n\n    # save the DFs in CSVs\n    fspDf.to_csv(fspCsvFile,index=False,mode='w+')\n    segDf.to_csv(segCsvFile,index=False,mode='w+')\n\n    #\n    # Create another table storing stream order network information with the columns:\n    # [\u2018StrOrd\u2019, \u2018DsStrOrd\u2019, \u2018JunctionFspX\u2019, \u2018JunctionFspY\u2019] for use in interpolting FSP DOF\n    #\n    strOrdDf = pd.DataFrame(columns=strOrdNetColumnNames)\n    strOrds = segDf['StrOrd'].drop_duplicates().sort_values().to_list()\n    for so in strOrds:\n        # find the most downstream segment in the stream order\n        mostDsSeg = segDf[segDf['StrOrd']==so].sort_values('DsDist')[['DsSegId']].head(1)\n        # print(mostDsSeg)\n        # get its downstream segment ID\n        dsSegId = mostDsSeg.iat[0,0]\n        if dsSegId != 0:\n            # get downstream stream order\n            dsOrd = segDf[segDf['SegId']==dsSegId]['StrOrd'].iat[0]\n            # get the first FSP in the downstream segment\n            firstFspXy = fspDf[fspDf['SegId']==dsSegId][['FspX','FspY']].head(1)\n            fspx, fspy = firstFspXy.iat[0,0], firstFspXy.iat[0,1]\n        else:\n            # no downstream segment\n            dsOrd,fspx,fspy = 0,0,0\n\n        # add the connectivity information to the table\n        temp = pd.DataFrame([[so,dsOrd,fspx,fspy]],columns=strOrdNetColumnNames)    \n        # append to the index table\n        # strOrdDf = strOrdDf.append(temp,ignore_index=True)\n        strOrdDf = pd.concat([strOrdDf, temp],ignore_index=True)\n\n    # save the table as a CSV file\n    strOrdCsvFile = os.path.join(libFolder, strOrdNetFileName)\n    strOrdDf.to_csv(strOrdCsvFile,index=False)\n\n    return fspDf, segDf, strOrdDf\n</code></pre>"},{"location":"tile/#fldpln.tile.ReadMatFile","title":"<code>ReadMatFile(matFile, varName)</code>","text":"<p>Read matlab files with different versions. scipy.io DOES NOT support MATLAB files version 7.3 yet! Some of the libraries are in 7.3 while the others are not.</p> <p>Parameters:</p> Name Type Description Default <code>matFile</code> <p>matlab file name</p> required <code>varName</code> <p>variable name in the matlab file</p> required Source code in <code>fldpln/tile.py</code> <pre><code>def ReadMatFile(matFile, varName):\n    \"\"\" Read matlab files with different versions. scipy.io DOES NOT support MATLAB files version 7.3 yet! Some of the libraries are in 7.3 while the others are not.\n        Parameters:\n            matFile: matlab file name\n            varName: variable name in the matlab file\n        Return: variable in the matlab file\n    \"\"\"\n\n    try: \n        # load the segment FSP-FPP-DTF table in mat file as &lt; 7.3. \n        vars = sio.loadmat(matFile)\n        var = vars[varName]\n    except NotImplementedError:\n        vars = {}\n        f = h5py.File(matFile,'r')\n        for k, v in f.items():\n            vars[k] = np.array(v)\n        # get the variable and transpose it for dataframe!\n        var = vars[varName].transpose()\n    except:\n        ValueError('Could not read the mat file at all...')\n        var = None\n\n    return var\n</code></pre>"},{"location":"tile/#fldpln.tile.TileLibrary","title":"<code>TileLibrary(segLibFolder, cellSize, tiledLibFolder, tileSize, fileFormat)</code>","text":"<p>Tile a library. Turn segment-based FSP-FPP relations to tile-based</p> <p>Parameters:</p> Name Type Description Default <code>segLibFolder</code> <p>folder containing the segment-based library</p> required <code>cellSize</code> <p>cell size in meters</p> required <code>tiledLibFolder</code> <p>folder for the tiled library</p> required <code>tileSize</code> <p>number of cells in a tile</p> required <code>fileFormat</code> <p>'snappy' or 'mat'. 'snappy' format needs to install the 'fastparquet' python package</p> required Source code in <code>fldpln/tile.py</code> <pre><code>def TileLibrary(segLibFolder, cellSize, tiledLibFolder, tileSize, fileFormat):\n    \"\"\" Tile a library. Turn segment-based FSP-FPP relations to tile-based\n        Parameters:\n            segLibFolder: folder containing the segment-based library\n            cellSize: cell size in meters\n            tiledLibFolder: folder for the tiled library\n            tileSize: number of cells in a tile\n            fileFormat: 'snappy' or 'mat'. 'snappy' format needs to install the 'fastparquet' python package\n        Return: metadata of the tiled library\n    \"\"\"\n    # This function uses the fsp_info.csv file (under tiledLibFolder) to get FSP IDs\n    # fileFormat: 'snappy' or 'mat'. 'snappy' format needs to install the 'fastparquet' python package\n    # tileSize changed to the number of cells on May 27, 2024 to avoid partial cells within a tile and also works for GCS system\n\n    # create the tiledLibFolder folder for all tiled libraries if it doesn't exist\n    os.makedirs(tiledLibFolder,exist_ok=True)\n\n    # \n    # copy FSP and segment info CSV files to tiled library folder\n    # \n    shutil.copyfile(os.path.join(segLibFolder, fspInfoFileName), os.path.join(tiledLibFolder, fspInfoFileName))\n    shutil.copyfile(os.path.join(segLibFolder, segInfoFileName), os.path.join(tiledLibFolder, segInfoFileName))\n\n    #\n    # save tile size, cell size and spatial reference in a metadata file \n    #\n    # read in spatial reference for the library\n    srFile = os.path.join(segLibFolder,prjFileName)\n    with open(srFile, 'r') as srf:\n        srText = srf.read()\n    metaData = {'TileSize': tileSize, 'CellSize': cellSize, 'SpatialReference': srText}\n    # save metedata\n    with open(os.path.join(tiledLibFolder, metaDataFileName), 'w') as jf:\n        json.dump(metaData,jf)\n\n    #\n    # calculate library and segment extents\n    libExt, segExts = CalculateLibraryExtent(segLibFolder,cellSize)\n    minX,maxX,minY,maxY = libExt\n\n    # Calculate tile boundaries\n    tb = CalculateTileBoundary(minX,maxX,minY,maxY,tileSize*cellSize,tileSize*cellSize)\n    print('Number of (possible) tiles:', len(tb))\n    print('Tile extents:\\n', tb, '\\n')\n\n    #\n    # Create tiles\n    #\n    print('Build tiles (tiling FSP-FPP relations) ...')\n    hcs = cellSize/2\n    # read in FSP ID and coordinates\n    # need to set float_precision='round_trip' to prevent rounding while reading the text file! float_precision='high' DOESN'T work.\n    # For Verdigris 10-m library, FSP ID of 22246, its FspX of -1003.7918248322967 in fsp_info.csv was read into memory as -1003.7918248322968 without using float_precision='round_trip'\n    fspIds = pd.read_csv(os.path.join(segLibFolder,fspInfoFileName),float_precision='round_trip',index_col=False)[['FspId','FspX','FspY']]\n\n    # initialize the index DFs and tile ID\n    fspIdxDf = pd.DataFrame(columns=fspIdxColumnNames)\n    tileIdxDf = pd.DataFrame(columns=tileIdxColumnNames)\n    tileId = 1\n    for t in tb:\n        print('Processing tile: ', tileId)\n\n        # tile boundary, not the cell center boundary!\n        tminX, tmaxX,tminY, tmaxY = t\n        print('Tile extent (minX, maxX, minY, maxY) :',(tminX, tmaxX,tminY, tmaxY))\n\n        # find the segments that intersect the tile rectangle\n        segs = segExts[~((segExts['MinX']&gt;tmaxX) | (segExts['MaxX']&lt;tminX))] # rectangles are NOT on left or right of each other\n        segs = segs[~((segs['MinY']&gt;tmaxY) | (segs['MaxY']&lt;tminY))] # rectangles are NOT on top or bottom of each other\n        segs = segs['FileName'].to_list()\n        print('Number of segments interseting with the tile: ', len(segs))\n\n        # find the FPP-FSP relations in the tile from all the intersecting segments\n        # Initialize the df\n        tdf = pd.DataFrame()\n        for mf in segs: #segMatFileFullNames:\n            # read mat file\n            matVar = ReadMatFile(mf,matRelVarName)\n            # converting array to a dataframe\n            sdf = pd.DataFrame(matVar, columns=matRelColumnNames)\n\n            # rename columns to better names\n            betterColumnNames = [\"FspX\", \"FspY\", \"FppX\", \"FppY\", \"Dtf\", \"FilledDepth\"]\n            d=dict(zip(matRelColumnNames,betterColumnNames))\n            sdf.rename(columns=d,inplace=True) # inplace changing column name\n\n            # Code used to find out which segment file (e.g., SLIE_segment40.mat) in library 'midkan\" has problem \n            # where column \u201cDTF + fill depth\u201d is LESS than the \"DTF\" column\n            # t  =  sdf['FilledDepth'] - sdf['Dtf']\n            # t  =  t &lt; -0.1\n            # if t.any():\n            #     print('Segment: ', mf)\n            #     print(f'Found negative depression in {mf}!')\n\n            # select the FPPs within the tile\n            sdf = sdf[(sdf['FppX']&gt;=tminX) &amp; (sdf['FppX']&lt;=tmaxX) &amp; (sdf['FppY']&gt;=tminY) &amp; (sdf['FppY']&lt;=tmaxY)].copy() # tell pandas we want a copy to avoid \"SettingWithCopyWarning\" in line 86 when there is only one segment mat file read\n            # print('Segment:', segId, 'Number of FSP-FPP relations:', len(sdf))\n            if tdf.empty:\n                tdf = sdf\n            else:\n                # tdf = tdf.append(sdf)\n                tdf = pd.concat([tdf, sdf])\n        print('Total number of FSP-FPP relations in the tile:', len(tdf))\n\n        # save the FSP-FPP relations and update the index dfs\n        if (not (tdf.empty)) and (len(tdf) != 0): # there are some FPPs in the tile\n            # #calculate FilledDepth\n            # tdf['FilledDepth'] = tdf['FilledDepth']-tdf['Dtf'] # This is NOT necessary as FLDPLN model output changed to save \"sink fill depth\" in v8. Modified by Xingong on 7/1/24\n\n            # Calculate FSP center extent for the tile\n            fspMinX = tdf['FspX'].min()\n            fspMaxX = tdf['FspX'].max()\n            fspMinY = tdf['FspY'].min()\n            fspMaxY = tdf['FspY'].max()\n\n            # Calculate FPP center extent within the tile\n            fppMinX = tdf['FppX'].min()\n            fppMaxX = tdf['FppX'].max()\n            fppMinY = tdf['FppY'].min()\n            fppMaxY = tdf['FppY'].max()\n\n            # turn FPP coordinates into row and column within the tile\n            # Note that the row and column start at (fppMinX, fppMaxY)!\n            tdf['FppX'] = ((tdf.FppX-fppMinX)/cellSize).round()\n            tdf['FppY'] = ((fppMaxY-tdf.FppY)/cellSize).round()\n            # tdf['FppIdx'] = tdf.FppX * tRows + tdf.FppY\n\n            # rename ['FppX','FppY'] to ['Col','Row']\n            tdf.rename(columns={'FppX':'FppCol','FppY':'FppRow'},inplace=True)\n\n            # merge relations with FSP IDs\n            tdf = tdf.merge(fspIds,how='left',on=['FspX','FspY'])\n\n            # # check FSP IDs\n            # if tdf.isnull().values.any():\n            #     print('There are NAN in the dataframe!')\n\n            # remove FspX &amp; FspY\n            tdf.drop(['FspX','FspY'],axis=1,inplace=True)\n\n            # reorder columns\n            tdf = tdf[relColumnNames]\n\n            # set datatypes for the columns\n            tdf=tdf.astype(dtype={\"FspId\":np.int32, \"FppCol\":np.int32, \"FppRow\":np.int32, \"Dtf\":np.float32, \"FilledDepth\":np.float32},copy=False)\n            # convert float64 to float32 before saving and create index on FspX and FspY for speed up merge during mapping\n            # tdf.astype(np.float32,copy=False).set_index(keys=['FspX','FspY'],inplace=True)\n\n            # save the relations in the tile in a file\n            print('Saving FSP-FPP relations in a file...')\n            if fileFormat == 'snappy':\n                # filePathName = os.path.join(segLibFolder, tileFileMainName+'_'+str(tileId)+'.gzip') # for gzip format\n                filePathName = os.path.join(tiledLibFolder, tileFileMainName+'_'+str(tileId)+'.snz') # for snappy format\n\n                # save to parquet file. Can only save one DataFrame!\n                # tdf.to_parquet(filePathName,engine='fastparquet',compression='gzip',index=False) # gzip\n                tdf.to_parquet(filePathName,engine='fastparquet',compression='snappy',index=False) # snappy fast processing\n                # tdf.to_parquet(filePathName,engine='fastparquet',compression='snappy',index=True) # snappy fast processing\n            elif fileFormat == 'mat':\n                # separate columns by datatypes (int32 and float32)\n                fspFppsArray = tdf[relColumnNames[0:3]].to_numpy(dtype=np.int32)\n                dtfFilledDepthArray = tdf[relColumnNames[-2::]].to_numpy(dtype=np.float32)\n                # Save to compressed .mat file\n                dfDic = {'FspFpps': fspFppsArray,'DtfFilledDepth': dtfFilledDepthArray}\n                # Tile cannot be too large which may cause failure in writing into .mat file. See https://github.com/scipy/scipy/issues/12465\n                filePathName = os.path.join(tiledLibFolder, tileFileMainName+'_'+str(tileId)+'.mat')\n                sio.savemat(filePathName, dfDic, do_compression=True) \n            else:\n                print('Unsupported file format!')\n                return\n\n            # calculate the min and max DTF for each FSPs in the tile\n            fspDf = tdf.groupby(['FspId'], as_index=False).agg(MinDtf = ('Dtf', min),MaxDtf = ('Dtf', max))\n            print('Number of unique FSPs in the tile:', len(fspDf))\n            # print(fspDf)\n\n            # add tile ID to fsp-tile index\n            fspDf['TileId'] = tileId\n            # reorder columns\n            fspDf = fspDf[fspIdxColumnNames]\n            # append to the index table\n            # fspIdxDf = fspIdxDf.append(fspDf,ignore_index=True)\n            fspIdxDf = pd.concat([fspIdxDf, fspDf], ignore_index=True)\n            # print('Fsp-Tile index for the tile:')\n            # print(fspIdxDf)\n\n            # Calculate FSP &amp; FPP external extents for saving in the tile-index file\n            fspMinX,fspMaxX,fspMinY,fspMaxY = fspMinX-hcs,fspMaxX+hcs,fspMinY-hcs,fspMaxY+hcs\n            fppMinX,fppMaxX,fppMinY,fppMaxY = fppMinX-hcs,fppMaxX+hcs,fppMinY-hcs,fppMaxY+hcs\n            print('Tile FSP extent (fspMinX,fspMaxX,fspMinY,fspMaxY): ', (fspMinX,fspMaxX,fspMinY,fspMaxY))\n            print('Tile FPP extent (fppMinX,fppMaxX,fppMinY,fppMaxY): ', (fppMinX,fppMaxX,fppMinY,fppMaxY))\n\n            # Calculate the min &amp; max DTF within the tile\n            minTileDtf = fspDf['MinDtf'].min()\n            maxTileDtf = fspDf['MaxDtf'].max()\n\n            # calculate number of relations and number of FPPs in the tile\n            numOfRels = len(tdf)\n            numOfFpps = len(tdf[['FppCol','FppRow']].drop_duplicates()) # groupby for fast?\n\n            # add tile ID and additional tile-related info to the tile index file\n            tileIdx = pd.DataFrame([[tileId,tminX,tmaxX,tminY,tmaxY,fppMinX,fppMaxX,fppMinY,fppMaxY,fspMinX,fspMaxX,fspMinY,fspMaxY,minTileDtf,maxTileDtf,numOfRels,numOfFpps]],columns=tileIdxColumnNames)\n            # append to the index table\n            # tileIdxDf = tileIdxDf.append(tileIdx,ignore_index=True)\n            tileIdxDf = pd.concat([tileIdxDf, tileIdx],ignore_index=True)\n            # print('Tile index for the tile:')\n            # print(tileIdxDf)\n\n            # move to the next tile\n            tileId +=1\n\n    # Save the index as a file\n    # print('Number of items in the fsp-tile index:', len(fspIdxDf))\n    # print('fsp-tile Index table:\\n',fspIdxDf)\n    # save index to a csv file\n    print('Save fsp-tile index as a CSV file ...')\n    fspIdxDf.to_csv(os.path.join(tiledLibFolder, tileFileMainName+'_fsp_index.csv'),index=False)\n\n    # print('Number of items in the tile-extent index:', len(tileIdxDf))\n    # print('Tile index table:\\n',tileIdxDf)\n    # save index to a csv file\n    print('Save tile index as a CSV file ...')\n    tileIdxDf.to_csv(os.path.join(tiledLibFolder, tileFileMainName+'_tile_index.csv'),index=False)\n\n    return metaData\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use fldpln in a project:</p> <pre><code>import fldpln\n</code></pre>"},{"location":"examples/intro/","title":"Intro","text":"In\u00a0[1]: Copied! <pre>print('Hello World!')\n</pre> print('Hello World!') <pre>Hello World!\n</pre>"}]}